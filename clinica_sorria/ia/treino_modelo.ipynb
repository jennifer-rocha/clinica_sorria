{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Description\n","\n","This notebook is baseline for caries segmentation on dental x-ray images for Panoramic Dental Dataset.\n","\n","For segmentation were used Unet + efficientnet_b0 architecture from segmentation_models_pytorch library.\n","\n","`If this notebook was helpful to you, please upvoite. Thank You!`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:02:11.104864Z","iopub.status.busy":"2023-07-02T18:02:11.104252Z","iopub.status.idle":"2023-07-02T18:02:22.017125Z","shell.execute_reply":"2023-07-02T18:02:22.01594Z","shell.execute_reply.started":"2023-07-02T18:02:11.104829Z"},"trusted":true},"outputs":[],"source":["! pip -q install segmentation_models_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:02:22.020968Z","iopub.status.busy":"2023-07-02T18:02:22.020311Z","iopub.status.idle":"2023-07-02T18:02:25.966019Z","shell.execute_reply":"2023-07-02T18:02:25.965028Z","shell.execute_reply.started":"2023-07-02T18:02:22.020927Z"},"trusted":true},"outputs":[],"source":["import os\n","import json\n","import warnings\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import segmentation_models_pytorch as smp\n","\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","\n","from sklearn.model_selection import train_test_split\n","from tqdm.notebook import tqdm\n","\n","\n","warnings.filterwarnings(action='ignore', category=UserWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:02:25.968009Z","iopub.status.busy":"2023-07-02T18:02:25.967649Z","iopub.status.idle":"2023-07-02T18:02:25.977126Z","shell.execute_reply":"2023-07-02T18:02:25.975941Z","shell.execute_reply.started":"2023-07-02T18:02:25.967971Z"},"trusted":true},"outputs":[],"source":["def seed_everything(seed=42):\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:02:25.980777Z","iopub.status.busy":"2023-07-02T18:02:25.980242Z","iopub.status.idle":"2023-07-02T18:02:26.021025Z","shell.execute_reply":"2023-07-02T18:02:26.020131Z","shell.execute_reply.started":"2023-07-02T18:02:25.980742Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["### Create CariesDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:02:26.025155Z","iopub.status.busy":"2023-07-02T18:02:26.024879Z","iopub.status.idle":"2023-07-02T18:02:26.037726Z","shell.execute_reply":"2023-07-02T18:02:26.037114Z","shell.execute_reply.started":"2023-07-02T18:02:26.025131Z"},"trusted":true},"outputs":[],"source":["class CariesDataset(Dataset):\n","    def __init__(self, images_path_list, labels_path_list, augmentation = True, device = 'cpu', image_size = (384, 768)):\n","        self.images = images_path_list\n","        self.labels = labels_path_list\n","        self.augmentation = augmentation\n","        self.device = device\n","\n","        self.transform = transforms.Compose([\n","            transforms.Resize(image_size),\n","            transforms.Grayscale(),\n","            transforms.ToTensor()\n","        ])\n","        \n","        if self.augmentation:\n","            self.same_augmentation = transforms.Compose([\n","                transforms.RandomRotation(degrees = 5),\n","                transforms.RandomHorizontalFlip(p = 0.5)\n","            ])\n","\n","            self.different_augmentation = transforms.Compose([\n","                transforms.RandomAdjustSharpness(2),\n","                transforms.ColorJitter(brightness=0.5, contrast=0.5)\n","            ])\n","\n","        \n","    def __getitem__(self, idx):\n","        image = Image.open(self.images[idx])\n","        label = Image.open(self.labels[idx])\n","        \n","        if self.augmentation:\n","            seed = np.random.randint(0, 10000)\n","            \n","            torch.random.manual_seed(seed)\n","            image = self.same_augmentation(image)\n","            image = self.different_augmentation(image)\n","            \n","            torch.random.manual_seed(seed)\n","            label = self.same_augmentation(label)\n","            \n","        image = self.transform(image).to(self.device)\n","        label = self.transform(label).to(self.device)\n","        \n","        label = 1. * (label != 0)\n","        \n","        return image, label\n","    \n","    def __len__(self):\n","        return len(self.images)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:02:26.039523Z","iopub.status.busy":"2023-07-02T18:02:26.038941Z","iopub.status.idle":"2023-07-02T18:02:26.058179Z","shell.execute_reply":"2023-07-02T18:02:26.057204Z","shell.execute_reply.started":"2023-07-02T18:02:26.039491Z"},"trusted":true},"outputs":[],"source":["image_path = 'images_cut/'\n","labels_path = 'labels_cut/'\n","\n","file_names = [filename for filename in os.listdir(image_path)]\n","train_files, val_files = train_test_split(file_names, test_size=0.2, random_state=42)\n","\n","\n","train_image_path = [image_path + file_name for file_name in train_files]\n","train_mask_path = [labels_path + file_name for file_name in train_files]\n","\n","eval_image_path = [image_path + file_name for file_name in val_files]\n","eval_mask_path = [labels_path + file_name for file_name in val_files]\n","\n","print(eval_image_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:02:26.060135Z","iopub.status.busy":"2023-07-02T18:02:26.059765Z","iopub.status.idle":"2023-07-02T18:02:26.06865Z","shell.execute_reply":"2023-07-02T18:02:26.067913Z","shell.execute_reply.started":"2023-07-02T18:02:26.060103Z"},"trusted":true},"outputs":[],"source":["train_dataset = CariesDataset(\n","    images_path_list = train_image_path,\n","    labels_path_list = train_mask_path,\n","    augmentation = True,\n","    device = device,\n",")\n","\n","eval_dataset = CariesDataset(\n","    images_path_list = eval_image_path,\n","    labels_path_list = eval_mask_path,\n","    augmentation = False,\n","    device = device,\n",")\n","\n","toPIL = transforms.ToPILImage()\n","\n","batch_size = 8\n","\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","\n","\n","eval_dataloader = DataLoader(eval_dataset, shuffle=False, batch_size=1)"]},{"cell_type":"markdown","metadata":{},"source":["### Create LossFunction and CalculateMetricFunction"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:02:26.070455Z","iopub.status.busy":"2023-07-02T18:02:26.06983Z","iopub.status.idle":"2023-07-02T18:02:26.082257Z","shell.execute_reply":"2023-07-02T18:02:26.081605Z","shell.execute_reply.started":"2023-07-02T18:02:26.070424Z"},"trusted":true},"outputs":[],"source":["class DiceLoss(nn.Module):\n","    def __init__(self, smooth = 1, activation = None):\n","        super(DiceLoss, self).__init__()\n","        self.smooth = smooth\n","        self.activation = activation\n","\n","    def forward(self, inputs, targets):\n","        if self.activation:\n","            inputs = self.activation(inputs)       \n","\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        \n","        intersection = (inputs * targets).sum()                            \n","        dice = (2. * intersection + self.smooth)/(inputs.sum() + targets.sum() + self.smooth)  \n","        \n","        return 1 - dice\n","    \n","\n","    \n","def metric_calculate(prediction: np.ndarray, target: np.ndarray):\n","\n","    target = np.uint8(target.flatten() > 0.5)\n","    prediction = np.uint8(prediction.flatten() > 0.5)\n","    TP = (prediction * target).sum()\n","    FN = ((1 - prediction) * target).sum()\n","    TN = ((1 - prediction) * (1 - target)).sum()\n","    FP = (prediction * (1 - target)).sum()\n","\n","    acc = (TP + TN) / (TP + TN + FP + FN + 1e-4)\n","    iou = TP / (TP + FP + FN + 1e-4)\n","    dice = (2 * TP) / (2 * TP + FP + FN + 1e-4)\n","    pre = TP / (TP + FP + 1e-4)\n","    spe = TN / (FP + TN + 1e-4)\n","    sen = TP / (TP + FN + 1e-4)\n","    \n","    return acc, iou, dice, pre, spe, sen"]},{"cell_type":"markdown","metadata":{},"source":["### Create model for semantic segmentation from SMP library"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:02:26.084458Z","iopub.status.busy":"2023-07-02T18:02:26.083512Z","iopub.status.idle":"2023-07-02T18:02:27.739573Z","shell.execute_reply":"2023-07-02T18:02:27.738522Z","shell.execute_reply.started":"2023-07-02T18:02:26.084426Z"},"trusted":true},"outputs":[],"source":["model = smp.UnetPlusPlus(\n","    encoder_name = 'efficientnet-b0',        \n","    encoder_weights = 'imagenet',     \n","    in_channels = 1,                  \n","    classes = 1,\n",").to(device)\n","\n","model_name = 'UNetEfficientnetB0'\n","\n","criterion = DiceLoss(activation=F.sigmoid)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n","\n","num_epoch = 50"]},{"cell_type":"markdown","metadata":{},"source":["### Training Process"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:02:46.098803Z","iopub.status.busy":"2023-07-02T18:02:46.098429Z","iopub.status.idle":"2023-07-02T18:14:36.558547Z","shell.execute_reply":"2023-07-02T18:14:36.557416Z","shell.execute_reply.started":"2023-07-02T18:02:46.098772Z"},"trusted":true},"outputs":[],"source":["print (f'Training {model_name} start.')\n","\n","IoU_max = 0.\n","losses_train, losses_val = [], []\n","metrics = []\n","\n","for epoch in tqdm(range(num_epoch)):\n","    current_train_loss, current_val_loss = 0., 0.\n","    current_metric = np.zeros(6)\n","\n","    model.train()\n","    for images, labels in train_dataloader:\n","        optimizer.zero_grad()\n","        logits = model(images)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        current_train_loss += loss.item() / len(train_dataloader)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for images, labels in eval_dataloader:\n","            logits = model(images)\n","            loss = criterion(logits, labels)\n","\n","            current_val_loss += loss.item() / len(eval_dataloader)\n","            current_metric += np.array(metric_calculate(\n","                logits.cpu().detach().numpy(), \n","                labels.cpu().detach().numpy())) / len(eval_dataloader)\n","\n","    losses_train.append(current_train_loss)\n","    losses_val.append(current_val_loss)\n","    metrics.append(current_metric.tolist())\n","\n","    if IoU_max < metrics[-1][1]:\n","        torch.save(model, f'{model_name}-best.pth')\n","        IoU_max = metrics[-1][1]\n","\n","    print (f'Epoch: {epoch + 1}, train_loss: {losses_train[-1]:.4f}, val_loss: {losses_val[-1]:.4f}, IoU: {metrics[-1][1]:.4f}')\n","\n","\n","log = {}\n","log['train_loss'] = losses_train \n","log['eval_loss'] = losses_val\n","log['metric'] = metrics\n","log['best_score'] = IoU_max\n","\n","torch.save(model, f'{model_name}-last.pth')\n","\n","with open(f'log.txt', 'w') as outfile:\n","    json.dump(log, outfile) \n","\n","torch.cuda.empty_cache()\n","\n","print ('- - ' * 30)\n","print (f'Training {model_name} done. Best IoU: {IoU_max:.4f}.')\n","print ('- - ' * 30)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:14:41.286535Z","iopub.status.busy":"2023-07-02T18:14:41.286125Z","iopub.status.idle":"2023-07-02T18:14:41.946197Z","shell.execute_reply":"2023-07-02T18:14:41.945294Z","shell.execute_reply.started":"2023-07-02T18:14:41.286503Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize = (12, 4))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(losses_train, label = 'train_loss')\n","plt.plot(losses_val, label = 'val_loss')\n","plt.grid()\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot([metric[1] for metric in metrics], label = 'IoU')\n","plt.axhline (IoU_max, linestyle = '--', color = 'red', label = f'IoU_max: {IoU_max:.4f}')\n","plt.grid()\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('IoU')\n","\n","plt.savefig('efficientnet-b0.png')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:30:28.775441Z","iopub.status.busy":"2023-07-02T18:30:28.774858Z","iopub.status.idle":"2023-07-02T18:30:28.975864Z","shell.execute_reply":"2023-07-02T18:30:28.974848Z","shell.execute_reply.started":"2023-07-02T18:30:28.775399Z"},"trusted":true},"outputs":[],"source":["model = torch.load('UNetEfficientnetB0-best.pth').eval()\n","image, label = eval_dataset[5]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:30:29.11365Z","iopub.status.busy":"2023-07-02T18:30:29.112863Z","iopub.status.idle":"2023-07-02T18:30:29.138798Z","shell.execute_reply":"2023-07-02T18:30:29.137923Z","shell.execute_reply.started":"2023-07-02T18:30:29.113581Z"},"trusted":true},"outputs":[],"source":["probabilities = F.sigmoid(model(image.unsqueeze(0))).squeeze(0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image, label = eval_dataset[5]\n","type(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T18:30:29.446489Z","iopub.status.busy":"2023-07-02T18:30:29.446085Z","iopub.status.idle":"2023-07-02T18:30:30.461019Z","shell.execute_reply":"2023-07-02T18:30:30.460171Z","shell.execute_reply.started":"2023-07-02T18:30:29.446458Z"},"trusted":true},"outputs":[],"source":["model = torch.load('UNetEfficientnetB0-best.pth').eval()\n","\n","image, label = eval_dataset[5]\n","probabilities = F.sigmoid(model(image.unsqueeze(0))).squeeze(0)\n","plt.figure(figsize = (16, 10))\n","\n","plt.subplot(1, 3, 1)\n","plt.imshow(toPIL(image), cmap='gray')\n","plt.title('Imagem enviada')\n","\n","plt.subplot(1, 3, 2)\n","plt.imshow(toPIL(probabilities), cmap='gray')\n","plt.title('Localização de Cáries')\n","\n","plt.subplot(1, 3, 3)\n","plt.imshow(toPIL(probabilities), alpha = 0.7, cmap='gray')\n","plt.imshow(toPIL(image), alpha=0.5, cmap='gray')\n","plt.title('Visão Geral')\n","\n","\n","plt.show()\n","plt.savefig('imagem_prevista.png')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from flask import Flask, request, send_file\n","from io import BytesIO\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","img = toPIL(probabilities)\n","\n","# Salvar a imagem em um objeto BytesIO\n","img_io = BytesIO()\n","img.save(img_io, 'JPEG')\n","img_io.seek(0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3419046,"sourceId":6067948,"sourceType":"datasetVersion"}],"dockerImageVersionId":30513,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
